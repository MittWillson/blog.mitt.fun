{"meta":{"title":"Mitt's Fun space!","subtitle":null,"description":"小学生 | 技术博客 | Mitt Willson","author":"Mitt Willson","url":"https://blog.mitt.fun","root":"/"},"pages":[{"title":"About Me","date":"2021-02-25T12:25:00.012Z","updated":"2021-02-25T12:25:00.012Z","comments":true,"path":"about/index.html","permalink":"https://blog.mitt.fun/about/index.html","excerpt":"","text":"我是 Mitt :( 在彻底分清楚谁是朋友之前不再列出我的朋友"},{"title":"","date":"2021-02-25T12:25:00.016Z","updated":"2021-02-25T12:25:00.016Z","comments":true,"path":"icons/manifest.json","permalink":"https://blog.mitt.fun/icons/manifest.json","excerpt":"","text":"{\"name\":\"App\",\"icons\":[{\"src\":\"/android-icon-36x36.png\",\"sizes\":\"36x36\",\"type\":\"image/png\",\"density\":\"0.75\"},{\"src\":\"/android-icon-48x48.png\",\"sizes\":\"48x48\",\"type\":\"image/png\",\"density\":\"1.0\"},{\"src\":\"/android-icon-72x72.png\",\"sizes\":\"72x72\",\"type\":\"image/png\",\"density\":\"1.5\"},{\"src\":\"/android-icon-96x96.png\",\"sizes\":\"96x96\",\"type\":\"image/png\",\"density\":\"2.0\"},{\"src\":\"/android-icon-144x144.png\",\"sizes\":\"144x144\",\"type\":\"image/png\",\"density\":\"3.0\"},{\"src\":\"/android-icon-192x192.png\",\"sizes\":\"192x192\",\"type\":\"image/png\",\"density\":\"4.0\"}]}"}],"posts":[{"title":"关于《Kubernetes 混合云用Kilo解决NAT节点通讯的问题》的那件事","slug":"kubernetes/k8s-混合云组网","date":"2021-02-25T05:07:29.000Z","updated":"2021-02-25T12:25:00.012Z","comments":true,"path":"service/kubernetes/2021/kubernetes/k8s-混合云组网/","link":"","permalink":"https://blog.mitt.fun/service/kubernetes/2021/kubernetes/k8s-%E6%B7%B7%E5%90%88%E4%BA%91%E7%BB%84%E7%BD%91/","excerpt":"pre-post()最近有在学习K8S相关，同时也将自己的所有服务全部都迁移到了K8S集群上，感受到K8S强大的同时也能明显感受到对于我这种一般用户环境的部署不是很友好，例如建议的高可用集群至少要有 三台 Master, 三台 Worker, 对我这种 穷逼 普通玩家来说是很高昂的，但经过几次实践把生产环境搞炸几次后觉得这是有必要的(哭)，但我的想法是用K8S作为我主要部署方式，所以还是非常高昂的，像我这种为了能够管理所有节点但是又不会重度使用K8S的，这里推荐 K3S 来代替K8S作为要求不高的生产环境，不过这篇文章还是用完整的K8S来做，但理论上 K3S 是完全通用的。","text":"pre-post()最近有在学习K8S相关，同时也将自己的所有服务全部都迁移到了K8S集群上，感受到K8S强大的同时也能明显感受到对于我这种一般用户环境的部署不是很友好，例如建议的高可用集群至少要有 三台 Master, 三台 Worker, 对我这种 穷逼 普通玩家来说是很高昂的，但经过几次实践把生产环境搞炸几次后觉得这是有必要的(哭)，但我的想法是用K8S作为我主要部署方式，所以还是非常高昂的，像我这种为了能够管理所有节点但是又不会重度使用K8S的，这里推荐 K3S 来代替K8S作为要求不高的生产环境，不过这篇文章还是用完整的K8S来做，但理论上 K3S 是完全通用的。 subject(‘实现目标’)利用 Kilo 将带有公网IP的NAT云服务器组成K8S集群，支持 P2P, DDNS (要求有公网IP且需要端口映射) subject(‘Kilo介绍’)Kilo 是一个通过 Wireguard 用于建立混合云网络的工具 subject(‘现有问题’)我的服务器构成是这样的(以下IP皆为虚拟): Name ifc-IP Location Role Nat k8s-master 123.123.123.123 Hetzner Master NO cn-sh01-node 10.0.0.4 QCloud Worker YES cn-hz01-node 192.168.1.120 Home Worker YES 可以看到我的三台服务器都不是同一个网段甚至都不是同一个服务商的。所以会有几个问题 kube-proxy 无法正常工作转发流量 metrics 采集无法工作 logs/shell 无法工作 subject(‘解决问题’)之前是用 Weave 来作为CNI的，然后为了解决 kube-proxy 的一些问题换成了 Flannel, 网上查找一些资料和issues以后发现如果要解决这个问题，就得先将所有节点连起来，连起来的方法就是VPN，然后让通讯流量走VPN接口即可解决，但是按常规理解VPN流量是需要中心服务器转发流量的，那就会导致所有流量转发到同一台服务器，压力和延迟也会非常大不符合需求，然后我去搜了P2P VPN发现 Wireguard 是支持Peer2Peer的，顺势在某个issue里看到有人提到用 Kilo 进行自动组网，并且 Kilo 是支持在 Flannel 之上运行的 端口通讯检查我是采用 Flannel+Calico+Kilo 的方式设置网络的，所以需要以下端口放通 Port Range Protocol Remark 8285 &nbsp;UDP&nbsp; Flannel 8472 &nbsp;UDP&nbsp; Flannel 51820 &nbsp;UDP&nbsp; Wireguard 默认端口 10250 &nbsp;TCP&nbsp; Kubelet API 30000-32767 &nbsp;TCP+UDP&nbsp; NodePort 服务端口 安装 KiloKubeadm 1$ kubectl apply -f https://raw.githubusercontent.com/squat/kilo/master/manifests/kilo-kubeadm-flannel.yaml 如果要卸载，直接 kubectl delete 就好了 配置外部连接IP由于目前尚未支持 NAT to NAT(理论可以实现)，所以每个Node都必须具备外部(公网)访问条件，但是你会发现一件事，每个Node都只会拿到网卡的IP，它没办法发现你的外部IP 所以就像 Flannel 通过 flannel.alpha.coreos.com/public-ip-overwrite 来覆写外部通讯IP一样 Kilo 同样也提供了 kilo.squat.ai/force-endpoint 来指定外部通讯连接点，格式是 &quot;IP:PORT&quot; 或者 &quot;[DOMAIN]:PORT&quot;，是的，它支持域名，所以就可以实现我们 HOME worker的DDNS需求，只要防火墙放通端口或者路由器转发端口就可以自由通讯了 编辑 cn-hz01-node 节点，在 metadata.annotations 里加入 kilo.squat.ai/force-endpoint: &#39;[home.mydomain.com]:51820&#39;，然后过一会通过 kubectl desc node cn-hz01-node 就可以看到它自动解析了域名并且添加了一个新的 kilo.squat.ai/endpoint annotation，值为你域名指向的IP 同样此方法去更改 cn-sh01-node 的 annotations，过一会就可以看到 metrics 信息已经正常显示了(前提是你已经部署了metrics采集) 建议采用 Flannel 的 vxlan 作为后端，不采用 IPSec 等加密后端避免不必要的二次开销 关于P2P实现 目前 Kilo 的P2P实现还在讨论并且已经在计划适配，具体可以在这里看到 https://github.com/squat/kilo/issues/109 subject(‘不通过VPN外部直连的可能性’)说个题外话，假如全部NODE都是有公网IP但是会有一层NAT的能不能正常通讯呢，这个读过一点Kubernetes的代码，这个是有可能的，就是更改Node的 status.addresses 添加一个 Type 为 ExternalIP 的IP地址，但是这里有个问题就是，你没办法直接编辑或者patch一个node的status值，那么这个addresses是怎么来的呢？ addresses 实际上是通过 cloud-provider 设置的，他读取你的网卡并将其IP设置为 InternalIP 的address, 如果你是GCE, Azure等，他们会去跟平台通讯获取你机器的外网绑定网卡信息，并且设置为 ExternalIP，而 metrics-server 的默认启动参数 --kubelet-preferred-address-types=ExternalIP,InternalIP,Hostname 定义了它会尝试去和外部IP、内部IP、主机名进行通讯，所以如果你是通过云服务商的k8s托管，那么它就会自动设置外部IP，但是手工设置是行不通的，所以如果自己写一个 “Fake” cloud-provider 的话也许也行得通，但其实价值就很低了，不如直接VPN组网来的实在。","categories":[{"name":"service","slug":"service","permalink":"https://blog.mitt.fun/categories/service/"},{"name":"kubernetes","slug":"service/kubernetes","permalink":"https://blog.mitt.fun/categories/service/kubernetes/"}],"tags":[{"name":"Wireguard","slug":"Wireguard","permalink":"https://blog.mitt.fun/tags/Wireguard/"},{"name":"Kilo","slug":"Kilo","permalink":"https://blog.mitt.fun/tags/Kilo/"},{"name":"Peer2Peer","slug":"Peer2Peer","permalink":"https://blog.mitt.fun/tags/Peer2Peer/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://blog.mitt.fun/tags/Kubernetes/"},{"name":"K8S","slug":"K8S","permalink":"https://blog.mitt.fun/tags/K8S/"},{"name":"K3S","slug":"K3S","permalink":"https://blog.mitt.fun/tags/K3S/"}]},{"title":"Docker - 给每个容器配置公网IP","slug":"docker/Docker-给每个容器配置公网IP","date":"2018-05-01T12:28:08.000Z","updated":"2021-02-25T11:57:00.000Z","comments":true,"path":"service/2018/docker/Docker-给每个容器配置公网IP/","link":"","permalink":"https://blog.mitt.fun/service/2018/docker/Docker-%E7%BB%99%E6%AF%8F%E4%B8%AA%E5%AE%B9%E5%99%A8%E9%85%8D%E7%BD%AE%E5%85%AC%E7%BD%91IP/","excerpt":"pre-post()为了方便部署流量转发服务，采用了Docker来干这个事，一般情况下一台节点只有一个IP，使用端口映射或者用参数 --network host 直接使用主机的网络来监听和转发是没有问题的，但是有一些节点会存在多个或一个段的外部IP，这时候虽然 IN 方向没有问题，但是 OUT 方向只会采用主机设置的默认路由来访问，就导致了转发的流量都使用同一个IP转发出去了，这是不对的，所以接下来就研究如何才能自定义出口流量，这篇文章则采用给容器配置外部IP的方式实现。 此方法适合非NAT主机","text":"pre-post()为了方便部署流量转发服务，采用了Docker来干这个事，一般情况下一台节点只有一个IP，使用端口映射或者用参数 --network host 直接使用主机的网络来监听和转发是没有问题的，但是有一些节点会存在多个或一个段的外部IP，这时候虽然 IN 方向没有问题，但是 OUT 方向只会采用主机设置的默认路由来访问，就导致了转发的流量都使用同一个IP转发出去了，这是不对的，所以接下来就研究如何才能自定义出口流量，这篇文章则采用给容器配置外部IP的方式实现。 此方法适合非NAT主机 subject(‘实现目标’)给每个 Docker 容器都配置不同的公网IP出口 solution(‘附加网络到容器’)12345678# 从 eth1 接口删除IP$ sudo ip addr del 192.168.33.10/24 dev eth1# 创建一个桥接名称为 “docker1” 的 shared_nw 网络$ sudo docker network create --driver bridge --subnet=192.168.33.0/24 --gateway=192.168.33.10 --opt &quot;com.docker.network.bridge.name&quot;=&quot;docker1&quot; shared_nw# 添加 “docker1” 到 eth1$ sudo brctl addif docker1 eth1 其中 192.168.33.0/24 是子网段, 192.168.33.10 是IP地址 123# 通过 curl 容器来验证IP结果$ docker run -it curlimages/curl --net shared_nw --ip 192.168.33.11 ip.sb# 输出结果: 192.168.33.11 这样这个容器本身的IP就变成了外部IP 弊端采用这种方法会把主机的IP剥离，如果你没有其他接入网卡的话会导致断网无法外部进入，只能通过 Console 来调整 参考来源 https://forums.docker.com/t/public-accessible-ip-in-container-like-bridge-network-in-virtualbox/3668/6 https://qiita.com/kjtanaka/items/f16757c1f0cc86ff225b solution(‘桥接网络IP’)12# 创建名为 &quot;pnet01&quot; 的 macvlan 网络$ docker network create -d macvlan --subnet 23.89.4.0/24 --gateway 23.89.4.1 -o parent=ens3 --aux-address=&quot;master=23.89.4.205&quot; pnet01 其中 23.89.4.0/24 是子网段, 23.89.4.1 是网关地址, ens3 是网卡接口名称, 23.89.4.205 是外部IP 123# 通过 curl 容器来验证IP结果$ docker run -it curlimages/curl --net pnet01 --ip 23.89.4.207 ip.sb# 输出结果: 23.89.4.207 其中 23.89.4.207 是要分配给容器的同网段的IP 其他信息主机 123456789101112131415# ifconfigens3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 23.89.4.205 netmask 255.255.255.0 broadcast 23.89.4.255 inet6 fe80::216:3cff:fe7e:fbeb prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:16:3c:7e:fb:eb txqueuelen 1000 (Ethernet) RX packets 96281 bytes 7457992 (7.1 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 5325 bytes 1603561 (1.5 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0# routeDestination Gateway Genmask Flags Metric Ref Use Ifacedefault 1.4-89-23.rdns. 0.0.0.0 UG 0 0 0 ens3localnet 0.0.0.0 255.255.255.0 U 0 0 0 ens3172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 容器内 12345678910111213# ifconfigeth0 Link encap:Ethernet HWaddr 02:42:17:59:04:CF inet addr:23.89.4.207 Bcast:0.0.0.0 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:27457 errors:0 dropped:0 overruns:0 frame:0 TX packets:579 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:1839527 (1.7 MiB) TX bytes:81473 (79.5 KiB)# routeDestination Gateway Genmask Flags Metric Ref Use Ifacedefault 1.4-89-23.rdns. 0.0.0.0 UG 0 0 0 eth023.89.4.0 * 255.255.255.0 U 0 0 0 eth0 弊端仅适用于拥有一个段的IP的服务器，采用这种方式的主机会保留一个IP用于通讯和桥接，然后分配同网段的其他IP给容器，如果有不同网段和网关的IP，就需要同样创建第二个网络 参考来源 https://docs.docker.com/network/network-tutorial-macvlan/#bridge-example https://www.aquasec.com/wiki/display/containers/Docker+Networking+101 subject(‘End’)这篇文章内容是 2018 年写的，一直摸鱼到 2021 年才补上，对现在的我来说对容器以及网络方面有了新的理解，所以这篇文章内容其实也算是有点 过时 了，还有一个方法是采用 iptables NAT进行实现，但是人工维护显然有些繁琐，虽然我没有再这个方向继续研究了，但是希望能给有需要的人一个参考。","categories":[{"name":"service","slug":"service","permalink":"https://blog.mitt.fun/categories/service/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.mitt.fun/tags/Docker/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-01-28T17:30:37.000Z","updated":"2021-02-25T12:25:00.012Z","comments":true,"path":"nihility/2018/hello-world/","link":"","permalink":"https://blog.mitt.fun/nihility/2018/hello-world/","excerpt":"","text":"Hello Everyone, I’m Mitt, and I wish you all Have fun every day!","categories":[],"tags":[{"name":"Milestone","slug":"Milestone","permalink":"https://blog.mitt.fun/tags/Milestone/"}]}],"categories":[{"name":"service","slug":"service","permalink":"https://blog.mitt.fun/categories/service/"},{"name":"kubernetes","slug":"service/kubernetes","permalink":"https://blog.mitt.fun/categories/service/kubernetes/"}],"tags":[{"name":"Wireguard","slug":"Wireguard","permalink":"https://blog.mitt.fun/tags/Wireguard/"},{"name":"Kilo","slug":"Kilo","permalink":"https://blog.mitt.fun/tags/Kilo/"},{"name":"Peer2Peer","slug":"Peer2Peer","permalink":"https://blog.mitt.fun/tags/Peer2Peer/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://blog.mitt.fun/tags/Kubernetes/"},{"name":"K8S","slug":"K8S","permalink":"https://blog.mitt.fun/tags/K8S/"},{"name":"K3S","slug":"K3S","permalink":"https://blog.mitt.fun/tags/K3S/"},{"name":"Docker","slug":"Docker","permalink":"https://blog.mitt.fun/tags/Docker/"},{"name":"Milestone","slug":"Milestone","permalink":"https://blog.mitt.fun/tags/Milestone/"}]}